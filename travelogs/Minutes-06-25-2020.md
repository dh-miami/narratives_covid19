# Meeting June 25th, 2020 

## 1. Translation

Complete the website translation, which is already in process (Many thanks to @Romina!):
    * Those of you who read Spanish can check the Spanish bio version and change whatever you want, https://covid.dh.miami.edu/es/equipo/ 
    * Missing translation for  [POST] “Hello World” https://covid.dh.miami.edu/2020/04/02/hello-world/ >> Hola Mundo https://covid.dh.miami.edu/es/2020/04/02/hola-mundo/ [Romina]
    * Missing translation for  [POST]  ¿Cómo hidratar un conjunto de Tweets? https://covid.dh.miami.edu/wp-admin/post.php?post=354&action=edit >> https://covid.dh.miami.edu/wp-admin/post.php?post=444&action=edit  [Romina]
    * Missing translation for  [POST]  “Analizar un corpus de Twitter con Voyant (I)” https://covid.dh.miami.edu/2020/06/11/analyzing-twitter-corpus-with-voyant/ > https://covid.dh.miami.edu/es/2020/06/11/analizar-un-corpus-de-twitter-con-voyant-i/  [Romina]
    * Susanna has translated general pages and revised Spanish versions for: "Recursos del proyecto", "Minería de Twitter y datasets sobre la Covid-19", "Covid-19 y educación superior", "¿Qué pueden decirnos las publicaciones académicas sobre el COVID-19 y la Educación?

Any volunteers to check grammar in these post before publishing??? 
 	 * What can academic journals tell us about covid-19? https://covid.dh.miami.edu/wp-admin/post.php?post=478&action=edit [Matt??]
 	 * Outbreak topics: Topic modeling of Covid-19: https://covid.dh.miami.edu/wp-admin/post.php?post=525&action=edit   [Ashley??] 

Once the Website is translated we will start to launch it, specially in DH channels.

Meeting notes: only three posts missing. Bios translated to English and Spanish. Once it is translated, it's time to launch and advertise, especially through DH channels.

## 2. Stopwords 

We need to create a unique list of stopwords combining these three. This way it will be simpler to run our scripts:

https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.extra.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-english.lst 

Meeting notes: probably easier to just create one stopwords list
- Nidia: issue with some words which should have access but don't. 
- Susanna: issue now is that we have three lists: English, Spanish, and COVID-related
	- need to add this overall list to Jerry's scripts as well
	- Jerry can change script and notebook to modify a file where you can input it instead
- Nidia: create one single list of stopwords
- MItsu: it could be dangerous to combine all of them. What if a new, updated version of stopwords adds others?
- Jerry: instead of sharing the list of files, maybe we can share a Python function that merges the two files together
	- Susanna: what is needed to do that?
	- Jerry: start with a list of Spanish stopwords that are beyond NOTK, or just put them all in one Spanish file. Then do the same for English.
- Mitsu: in case of Twitter, where there is a limit to length - what about acronyms? (IMHO, etc.)
	- some may have the same letters as stopwords we want to remove
- Susanna: are there stopwords for Twitter?
- Nidia: it would be nice to create an acronym dictionary for Twitter
- Susanna: so it seems wiser to just keep two, then.
- Mitsu: example: ill vs I'll - Twitter discourse sometimes removes punctuation/capitalization
- Nidia: this is why it's important to have our own file that we can edit. 
- Susanna: can a list file have comments?
	- Jerry: we can do it. Whatever reads the .txt needs to know what a comment is. Not a bad idea, if you want to do a soft delete of a stopword. You can put a # in front of it


## 3. “Workshops” / Info Sessions
@Jerry and @Nidia have done a very cool job writing several scripts. @Jerry has focused on frequency, while @Nidia is applying topic modelling techniques. Both of them share the script through a Jupyter notebook: 

https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/freq_viz_race.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/top_ngrams.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/topic_modelling/topic_modelling_exploration.ipynb 

Susanna will open up a Doodle to check availability before July 15th. Any preferences?

Meeting notes: Susanna: proposal, especially for Matt and Ashley, is for Jerry and Nidia to do a one-hour info session explaining what they have done
	- it would be nice for you to have training
	- sent over password for the root - the idea is to keep the Jupyter notebook in the server and work that way
	- maybe we can have a session and go through the script, send instructions to install Jupyter/Anaconda/etc beforehand
	- Jerry: we should do it through URL/VPN
	- Susanna: we need to install a SSL certificate, but it will take a while, as UM has to do it
	- We only want the server for the Jupyter notebook
		- Jerry: we could hydrate tweets that way too, though, and should move the majority of the work to the server
	- Mid-July, that should be working
	- could be issues with Argentina and VPN
	- Jerry: you need to tunnel - get into a public machine on UM and then get into your own machine; the person needs a login
	- Susanna: will send out a Doodle poll for the info session to occur before July 10


## 4. Posts 

We need to organize our work during this upcoming month of July.

### Individual posts?? 

* Idea 1 
* Idea 2 

### Collaborative posts??  
A new series of blog posts to be done after @Jerry’s and @Nidia’s sessions should get started then. First of all, I propose a collaborative post using Jerry’s script on frequencies where we will: 
- Check two posts started by Susanna: 
   * https://covid.dh.miami.edu/?p=601 
   * https://covid.dh.miami.edu/?p=614 
   
- Divide our corpus per weeks
- Look for the 100 most frequent words in each area/country (Florida En, Es, Ar, Co, Pe, Mx, Ec, Es, Co) 
- Most 20 frequent hashtags in each area/country
- Visualize results like the tables in this post: https://medium.com/swlh/nlp-text-visualization-twitter-sentiment-analysis-in-r-65b14240258f “Top words per Twitter source” 
- Bring out some conclusions. 

Meeting notes: - Susanna: the posts. My idea with Gimena is for everyone, especially DH fellows, to write something of their own. I suggest you take advantage of the text - if you start working with a new dataset or hydrating data, that's a ton of work. I suggest you concentrate on what we have done. My idea is that maybe Matt could postl one of his findings about countries, and which countries are appearing.
	- two links from Slack:
	- first: Frequency Analysis of Terms in South Florida from April to June using Jerry's script (Spanish and English)
	- comparing top English and Spanish words, using bigrams and trigrams as well
	- comparing findings from these: why does English include "business" but not Spanish?
	- second: comparing top words by country: Argentina, Colombia, Ecuador, Spain, Mexico, and Peru
	- so this could be a post for some of us to take on and collaborate on

- Matt: what I've found more useful is looking at Voyant over longer periods of time, rather than week by week. When uploading the entire corpus with daily tweets as a different file, I was able to track how ideas and terms shift over time. I'd like to look at how the English population of Miami is treating COVID versus the rest of the world. Miami is very insular, despite it being such a global city. There are places being talked about but paling compared to the rest of the world/country. I'm thinking of a blog post based on that.
	- Susanna: maybe I can help you out with the Spanish side of this

- Ashley: working with Empath and sentiment analysis. Maybe help with Susanna and Spanish. Also interested in changes over time for the South Florida corpus: whether the quantity of tweets increases or decreases over time, whether there are any times of day that are more popular than others, whether other events interrupt this.

- Susanna: I would like to compare South Florida in English and Spanish, and then all the Spanish corpus. We could also add in topic modeling.
	- Ashley: can check Nidia's post in English
	- Matt: can check Gimena's and Marisol's posts
	- notify team once they are edited so we can post
   
- Susanna: I have a list of functions for Jerry to add to the script. Like a code for unique words that are happening in one specific area.
	- Nidia: there is already a function for importing topic modeling results
	- Jerry: bigram visualizations
	- Susanna: can we create the top hashtags as well as top words?
	- Nidia: Jerry and I probably need to make sure we do things the same way--agree on same criteria for bigrams, etc. so we can get the same results

## 5. License 

We are still waiting for UM Library to answer us about the sharing policy of our tweets. The most probable is that we won’t have problems publishing the processed tweets. What we cannot do is to share Tweets with Users. 

## 6. Server 

New server has been “built” but we are still having some issues… For now, we need to connect to the server with the UM VPN, so those who are not from UM won’t be able to do so. We have root access and it is using Centos 8 and Python 3.6. The first steps will be to install the list @Nidia and @Jerry gave, to install Jupyter Notebook, and see how we make the url public. 
