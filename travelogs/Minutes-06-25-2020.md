# Meeting June 25th, 2020 

1) Complete the website translation, which is already in process (Many thanks to @Romina!):
    * Those of you who read Spanish can check the Spanish bio version and change whatever you want, https://covid.dh.miami.edu/es/equipo/ 
    * Missing translation for Gimena bio [Gimena]
    * Missing translation for  [POST] “Hello World” https://covid.dh.miami.edu/2020/04/02/hello-world/ >> Hola Mundo https://covid.dh.miami.edu/es/2020/04/02/hola-mundo/ [Romina]
    * Missing translation for  [POST]  ¿Cómo hidratar un conjunto de Tweets? https://covid.dh.miami.edu/wp-admin/post.php?post=354&action=edit >> https://covid.dh.miami.edu/wp-admin/post.php?post=444&action=edit  [Romina]
    * Missing translation for  [POST]  “Analizar un corpus de Twitter con Voyant (I)” https://covid.dh.miami.edu/2020/06/11/analyzing-twitter-corpus-with-voyant/ > https://covid.dh.miami.edu/es/2020/06/11/analizar-un-corpus-de-twitter-con-voyant-i/  [Romina]
    * I has translated general pages and revised Spanish versions for: "Recursos del proyecto", "Minería de Twitter y datasets sobre la Covid-19", "Covid-19 y educación superior", "¿Qué pueden decirnos las publicaciones académicas sobre el COVID-19 y la Educación?
   * Could an English native check these post before publishing, please: 
 	 * What can academic journals tell us about covid-19? https://covid.dh.miami.edu/wp-admin/post.php?post=478&action=edit [Matt??]
 	 * Outbreak topics: Topic modeling of Covid-19: https://covid.dh.miami.edu/wp-admin/post.php?post=525&action=edit   [Ashley??] 

Once the Website is translated we will start to launch it, specially in DH channels. Please, keep you updated with the new posts we have: Gimena and Marisol, and Nidia!! 

2) We need to create a unique list of stopwords combining these three [Nidia??]. This way it will be simpler to run our scripts:
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.extra.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-english.lst 

3) “Workshops” / Info Sessions
@Jerry and @Nidia have done a very cool job writing several scripts. @Jerry has focused on frequency, while @Nidia is applying topic modelling techniques. Both of them share the script through a Jupyter notebook: 

https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/freq_viz_race.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/top_ngrams.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/topic_modelling/topic_modelling_exploration.ipynb 

I know not all of you are familiar with Jupyter notebook, so we thought it would be a good opportunity for all of us if @Jerry and @Nidia teach us how to use it and explain each part of their script, so we can all work with these scripts as well. We will open up a Doodle to check availability before July 15th. 

4) Posts 

We need to organize our work during this upcoming month of July. Specially, DH Fellows should write one or two posts before August :) 

Matt: How about you continue your exploration of Countries with Voyant? Here you have different possibilities. For example, you can concentrate on a timelapse, say you take May 2020, and see in each area of our corpus which countries are most cited. OR, you could compare our Florida corpus with the rest of US for one week that you consider relevant. For this, you should have to hydrate part of the corpus in the Panacea Lab. The post could be an opportunity to reflect on international connections. Just an idea.
[Ashley]: Update me about your work on Users and Retweets and hydrating our dataset. This could be a good exercise, but it will take you more time, as we talked. 
A new series of blog posts to be done after @Jerry’s and @Nidia’s sessions should get started then. First of all, I propose a collaborative post using Jerry’s script on frequencies where we will: 
Divide our corpus per weeks
Look for the 100 most frequent words in each area/country (Florida En, Es, Ar, Co, Pe, Mx, Ec, Es, Co) 
Most 20 frequent hashtags in each area/country
Visualize results like the tables in this post: https://medium.com/swlh/nlp-text-visualization-twitter-sentiment-analysis-in-r-65b14240258f “Top words per Twitter source” 
Bring out some conclusions. 
Tomorrow we can talk how to divide the work and if you have some preferences. :) 

Questions still pending: :(
5. We are still waiting for UM Library (Cameron) to answer us about the sharing policy of our tweets. The most probable is that we won’t have problems publishing the processed tweets. What we cannot do is to share Tweets with Users. << NB. @Ashley and @Matt wanted this information, but we suggest that we concentrate for now only in texts from April / May onwards. 

6. New server has been “built” but we are still having some issues… For now, we need to connect to the server with the UM VPN, so those who are not from UM won’t be able to do so. We have root access and it is using Centos 8 and Python 3.6. The first steps will be to install the list @Nidia and @Jerry gave, to install Jupyter Notebook, and see how we make the url public. 
