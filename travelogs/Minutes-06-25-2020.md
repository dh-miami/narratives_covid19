# Meeting June 25th, 2020 

## 1. Translation

Complete the website translation, which is already in process (Many thanks to @Romina!):
    * Those of you who read Spanish can check the Spanish bio version and change whatever you want, https://covid.dh.miami.edu/es/equipo/ 
    * Missing translation for  [POST] “Hello World” https://covid.dh.miami.edu/2020/04/02/hello-world/ >> Hola Mundo https://covid.dh.miami.edu/es/2020/04/02/hola-mundo/ [Romina]
    * Missing translation for  [POST]  ¿Cómo hidratar un conjunto de Tweets? https://covid.dh.miami.edu/wp-admin/post.php?post=354&action=edit >> https://covid.dh.miami.edu/wp-admin/post.php?post=444&action=edit  [Romina]
    * Missing translation for  [POST]  “Analizar un corpus de Twitter con Voyant (I)” https://covid.dh.miami.edu/2020/06/11/analyzing-twitter-corpus-with-voyant/ > https://covid.dh.miami.edu/es/2020/06/11/analizar-un-corpus-de-twitter-con-voyant-i/  [Romina]
    * Susanna has translated general pages and revised Spanish versions for: "Recursos del proyecto", "Minería de Twitter y datasets sobre la Covid-19", "Covid-19 y educación superior", "¿Qué pueden decirnos las publicaciones académicas sobre el COVID-19 y la Educación?

Any volunteers to check grammar in these post before publishing??? 
 	 * What can academic journals tell us about covid-19? https://covid.dh.miami.edu/wp-admin/post.php?post=478&action=edit [Matt??]
 	 * Outbreak topics: Topic modeling of Covid-19: https://covid.dh.miami.edu/wp-admin/post.php?post=525&action=edit   [Ashley??] 

Once the Website is translated we will start to launch it, specially in DH channels.

## 2. Stopwords 

We need to create a unique list of stopwords combining these three. This way it will be simpler to run our scripts:

https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-spa.extra.lst
https://github.com/dh-miami/narratives_covid19/blob/master/resources/stopwords-english.lst 

## 3. “Workshops” / Info Sessions
@Jerry and @Nidia have done a very cool job writing several scripts. @Jerry has focused on frequency, while @Nidia is applying topic modelling techniques. Both of them share the script through a Jupyter notebook: 

https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/freq_viz_race.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/freq_analysis/top_ngrams.ipynb
https://github.com/dh-miami/narratives_covid19/blob/master/scripts/topic_modelling/topic_modelling_exploration.ipynb 

Susanna will open up a Doodle to check availability before July 15th. Any preferences?

## 4. Posts 

We need to organize our work during this upcoming month of July.

### Individual posts?? 

* Idea 1 
* Idea 2 

### Collaborative posts??  
A new series of blog posts to be done after @Jerry’s and @Nidia’s sessions should get started then. First of all, I propose a collaborative post using Jerry’s script on frequencies where we will: 
- Check two posts started by Susanna: 
   * https://covid.dh.miami.edu/?p=601 
   * https://covid.dh.miami.edu/?p=614 
   
- Divide our corpus per weeks
- Look for the 100 most frequent words in each area/country (Florida En, Es, Ar, Co, Pe, Mx, Ec, Es, Co) 
- Most 20 frequent hashtags in each area/country
- Visualize results like the tables in this post: https://medium.com/swlh/nlp-text-visualization-twitter-sentiment-analysis-in-r-65b14240258f “Top words per Twitter source” 
- Bring out some conclusions. 

## 5. License 

We are still waiting for UM Library to answer us about the sharing policy of our tweets. The most probable is that we won’t have problems publishing the processed tweets. What we cannot do is to share Tweets with Users. 

## 6. Server 

New server has been “built” but we are still having some issues… For now, we need to connect to the server with the UM VPN, so those who are not from UM won’t be able to do so. We have root access and it is using Centos 8 and Python 3.6. The first steps will be to install the list @Nidia and @Jerry gave, to install Jupyter Notebook, and see how we make the url public. 
